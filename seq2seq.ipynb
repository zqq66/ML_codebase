{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItBzhio-_I0F",
        "outputId": "c632cc80-4760-4746-80d7-779b9ed4889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5e1hDxGKLbR"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.legacy.data import Field,BucketIterator, TabularDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import spacy\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EivoYsBOZgRl"
      },
      "outputs": [],
      "source": [
        "MAXLENGTH = 10\n",
        "BATCHSIZE = 128\n",
        "\n",
        "\n",
        "train_path = 'drive/My Drive/CMPUT499/seq2seq/data_30k_re.csv'\n",
        "test_path = 'drive/My Drive/CMPUT499/seq2seq/data_test_30k_re.csv'\n",
        "valid_path = 'drive/My Drive/CMPUT499/seq2seq/data_valid_30k_re.csv'\n",
        "SRC = Field(lower=True, \n",
        "            init_token=\"<sos>\", \n",
        "            eos_token=\"<eos>\",\n",
        "            fix_length=MAXLENGTH,\n",
        "            include_lengths=True)\n",
        "\n",
        "TRG = Field(lower=True, \n",
        "            init_token=\"<sos>\", \n",
        "            eos_token=\"<eos>\",\n",
        "            fix_length=MAXLENGTH)\n",
        "\n",
        "\n",
        "train_data = TabularDataset(train_path, \n",
        "                      format=\"csv\", \n",
        "                      skip_header=True,\n",
        "                      fields=[(\"src\", SRC), (\"trg\", TRG)])\n",
        "\n",
        "valid_data = TabularDataset(valid_path, \n",
        "                      format=\"csv\", \n",
        "                      skip_header=True,\n",
        "                      fields=[(\"src\", SRC), (\"trg\", TRG)])\n",
        "\n",
        "test_data = TabularDataset(test_path, \n",
        "                      format=\"csv\", \n",
        "                      skip_header=True,\n",
        "                      fields=[(\"src\", SRC), (\"trg\", TRG)])\n",
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y0ugd3MMMxG9"
      },
      "outputs": [],
      "source": [
        "SRC.build_vocab(train_data)\n",
        "TRG.build_vocab(train_data)\n",
        "print(SRC.vocab.stoi)\n",
        "print(TRG.vocab.stoi)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "            (train_data, valid_data, test_data), \n",
        "              batch_size = BATCHSIZE,\n",
        "              sort_within_batch = True,\n",
        "              sort_key=lambda x: len(x.src),\n",
        "              sort=True,\n",
        "              device = device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BqZfrt8YO-UE"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers)\n",
        "        \n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(src)\n",
        "        \n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu())\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                                 \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        # print(\"outputs\", outputs)\n",
        "        # print(\"hidden\", hidden)\n",
        "        # print(\"hidden\", hidden)\n",
        "            \n",
        "        # outputs= self.rnn(embedded)\n",
        "        # print(outputs)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H4kzrv1RYFuY"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.embedding(input)\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # print(prediction)\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aSc75lpqYFuZ"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden = self.encoder(src, src_len)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "02LBw_jgPMJ_"
      },
      "outputs": [],
      "source": [
        "# size of vocabulary\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "\n",
        "ENC_EMB_DIM = 512\n",
        "DEC_EMB_DIM = 512\n",
        "# ENC_HID_DIM = 15\n",
        "# DEC_HID_DIM = 15\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "atTNk8BBYFub"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        # print(\"src.shape\", src.shape)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pAKhXHlaQASs"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item() # add loss iteratively from batch\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yQFnI_cbRO3W"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = MAXLENGTH):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    # print(\"token with eos, sos\", tokens)\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "    # print(\"token encoded\", src_indexes)\n",
        "    \n",
        "    src_indexes += [src_field.vocab.stoi[src_field.pad_token] for i in range(max_len-len(src_indexes))] \n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "    # print(\"token tensor\", src_indexes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor, src_len)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "        trg_indexes.append(pred_token)\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]\n",
        "\n",
        "# model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "# src = ['a', 'b', 'c', 'd']\n",
        "# translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "# print('predicted trg = {', translation,'}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FxmH7ZGiYFuc",
        "outputId": "a17b9d69-a621-49e9-db20-5c06c0bdc669"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Train BLEU: 0.809 | Exact Match Accuracy: 0.079 |\n",
            "model saved in 0\n",
            "\tTrain Loss: 1.807 | Train PPL:   6.095\n",
            "\t Val. Loss: 1.239 |  Val. PPL:   3.454\n",
            "| Train BLEU: 0.999 | Exact Match Accuracy: 0.960 |\n",
            "model saved in 1\n",
            "\tTrain Loss: 0.612 | Train PPL:   1.844\n",
            "\t Val. Loss: 0.203 |  Val. PPL:   1.225\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 0.998 |\n",
            "model saved in 2\n",
            "\tTrain Loss: 0.089 | Train PPL:   1.093\n",
            "\t Val. Loss: 0.045 |  Val. PPL:   1.046\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "model saved in 3\n",
            "\tTrain Loss: 0.029 | Train PPL:   1.029\n",
            "\t Val. Loss: 0.021 |  Val. PPL:   1.021\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "model saved in 4\n",
            "\tTrain Loss: 0.015 | Train PPL:   1.015\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "model saved in 5\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "model saved in 6\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.006\n",
            "\t Val. Loss: 0.006 |  Val. PPL:   1.006\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "\t Val. Loss: 0.005 |  Val. PPL:   1.005\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.004 |  Val. PPL:   1.004\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.003 |  Val. PPL:   1.003\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "model saved in 10\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.002 |  Val. PPL:   1.002\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.002 |  Val. PPL:   1.002\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.002 |  Val. PPL:   1.002\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "| Train BLEU: 1.000 | Exact Match Accuracy: 1.000 |\n",
            "\tTrain Loss: 0.000 | Train PPL:   1.000\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_bleu = float('-inf')\n",
        "\n",
        "train_loss_lst = []\n",
        "valid_loss_lst = []\n",
        "train_bleu_lst = []\n",
        "test_bleu_lst = []\n",
        "train_exact_match_lst = []\n",
        "test_exact_match_lst = []\n",
        "\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    train_loss_lst.append(train_loss)\n",
        "    valid_loss_lst.append(valid_loss)\n",
        "\n",
        "    train_BLEU = 0\n",
        "    train_exact_match = 0\n",
        "    for i in range(len(train_data)):\n",
        "      src = train_data[i].src\n",
        "      # print(f'src = {src}')\n",
        "\n",
        "      translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "      trg = train_data[i].trg\n",
        "      # print(f'trg = {trg}')\n",
        "      # print(f'translation = {translation}')\n",
        "\n",
        "      train_BLEU += float(nltk.translate.bleu_score.modified_precision([trg], translation, n=1))\n",
        "      # print(train_BLEU/(i+1))\n",
        "      if trg == translation:\n",
        "        train_exact_match += 1\n",
        "        \n",
        "    train_BLEU /= len(train_data)\n",
        "    train_exact_match /= len(train_data)\n",
        "    train_bleu_lst.append(train_BLEU)\n",
        "    train_exact_match_lst.append(train_exact_match)\n",
        "\n",
        "\n",
        "    test_BLEU = 0\n",
        "    test_exact_match = 0\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "      src = test_data[i].src\n",
        "      # print(f'src = {src}')\n",
        "\n",
        "      translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "      trg = test_data[i].trg\n",
        "      # print(f'trg = {trg}')\n",
        "      # print(f'translation = {translation}')\n",
        "\n",
        "      test_BLEU += float(nltk.translate.bleu_score.modified_precision([trg], translation, n=1))\n",
        "\n",
        "      if trg == translation:\n",
        "        test_exact_match += 1\n",
        "\n",
        "    test_BLEU /= len(test_data)\n",
        "    test_exact_match /= len(test_data)\n",
        "    test_bleu_lst.append(test_BLEU)\n",
        "    test_exact_match_lst.append(test_exact_match)\n",
        "\n",
        "    \n",
        "    print(f'| Train BLEU: {train_BLEU:.3f} | Exact Match Accuracy: {train_exact_match:.3f} |')\n",
        "\n",
        "  \n",
        "    if train_exact_match > best_bleu:\n",
        "        best_bleu = train_exact_match\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "        print('model saved in', epoch)\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "# plotting result\n",
        "epochs = range(1, N_EPOCHS + 1)\n",
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('index of Epoch')\n",
        "ax1.set_ylabel('Train Exact Match', color=color)\n",
        "l1 = ax1.plot(epochs, train_exact_match_lst, color=color, label= \"Train Exact Match\")\n",
        "# ax1.legend(loc=\"upper right\")\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "colorSet = [\"blue\", \"orange\", \"purple\", \"green\", \"gray\"]\n",
        "\n",
        "i = 0\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "# color = 'tab:blue'\n",
        "ax2.get_shared_y_axes().join(ax1, ax2)\n",
        "color = 'tab:'+colorSet[i]\n",
        "ax2.set_ylabel('Test Exact Match', color=color)  # we already handled the x-label with ax1\n",
        "l3 = ax2.plot(epochs, test_exact_match_lst, color=color, label = \"Test Exact Match\")\n",
        "ax2.tick_params(axis='y', labelcolor=color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EcIpIHMlRiTE"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hClTNg74Rxs0"
      },
      "outputs": [],
      "source": [
        "BLEU = 0\n",
        "exact_match = 0\n",
        "print(len(train_data))\n",
        "for i in range(0, len(train_data)):\n",
        "  src = train_data[i].src\n",
        "  # print(f'src = {src}')\n",
        "\n",
        "  translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "  trg = train_data[i].trg\n",
        "  # print(f'trg = {trg}')\n",
        "  # print(f'translation = {translation}')\n",
        "\n",
        "  BLEU += float(nltk.translate.bleu_score.modified_precision([trg], translation, n=1))\n",
        "  \n",
        "  if trg == translation:\n",
        "    exact_match += 1\n",
        "\n",
        "BLEU /= len(train_data)\n",
        "exact_match /= len(train_data)\n",
        "print(f'| Train BLEU: {BLEU:.3f} | Exact Match Accuracy: {exact_match:.3f} |')\n",
        "\n",
        "\n",
        "BLEU = 0\n",
        "exact_match = 0\n",
        "for i in range(0, len(test_data)):\n",
        "  src = test_data[i].src\n",
        "  # print(f'src = {src}')\n",
        "\n",
        "  translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "  trg = test_data[i].trg\n",
        "  # print(f'trg = {trg}')\n",
        "  # print(f'translation = {translation}')\n",
        "  BLEU += float(nltk.translate.bleu_score.modified_precision([trg], translation, n=1))\n",
        "\n",
        "  if trg == translation:\n",
        "    exact_match += 1\n",
        "\n",
        "BLEU /= len(test_data)\n",
        "exact_match /= len(test_data)\n",
        "print(f'| Test BLEU: {BLEU:.3f} | Exact Match Accuracy: {exact_match:.3f} |')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2ByMz8b9K7dV"
      },
      "outputs": [],
      "source": [
        "src = ['a', 'b', 'c', 'd']\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print('predicted trg = {', translation,'}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "seq2seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}